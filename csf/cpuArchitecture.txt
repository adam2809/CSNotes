>>ALU:
-Usually multi-bit one out and two in
-Performs mathematical, bitwise operations -> its behavior is dynamic
-Its functionality is controlled by additional pins
-The amount of circutry can be optimised by for example not implementing subtraction operation
and replacing it by adding positive and nagative numbers or ignoring the OR operation
which can be performed with NOT and AND(De Morgan laws). This is beneficial as less
gates mean lower cost and faster speed of travel of signals through the CPU
-The Multiplexor is used to control the functionality of the ALU (a, b, sel -> if sel than a else b -> out)
so essentially we have to perform every operation the ALU is capable of and than select
(sel in Mux stands for select) the approperiate values(using control pins as sel)
-Subtraction works by (assuming ALU: x,y -> out) inverting x, adding x to y and inverting
the out. To convert positive to negative in U2 you invert bits and add 1 so subtraction works like this:
TODO figure out subrtraction in ALU

>>von Neumann model:

MEMORY             CPU
|----|            |----|
|    | data bus   |    |
|    |<---------->|    |<--------- IN
|    | adress bus |    |
|    |----------->|    |---------> OUT
|    |            |    |
|----|            |----|
                    ^
                inside:
                #ALU
                #Registers
                #Control Logic
-this model allows to change behavior of the computer by altering instructions and data in memory
even though everything is still built with simple combinatotial logic
-von Neumann bottleneck - CPU can only fetch program instructions or data

>>6502
-8-bi
-3 8-bit registers plus Stack Pointer and Processor Status:
  #A - the Accumulator;performs arithmetic and logic operations
  #X and Y;temporary storage
-most instructions use the Accumulator as a primary destination for operation result storing (A = A op something)
the X and Y registers can only be incremented etc. so they are mostly used as counters or sth like that
-uses only one adress per instruction(to add do ADC #3 this is not a problem as you can only add a value to the
one that is alredy stored in the accumulator) (680000 uses two addresses, ARM uses 3)
-nearly all elementary instaructions can be implamenterd with the same sequence:
  #store ALU A register with the Accumulator
  #store ALU B register with the value specified
  #set ALU function and store the output in the accumulator

>>SR latch, D latch/filip-flops(TODO revise D latch/flipflop) slides 02.11.18

>>
-used to model sequential logic circuts
-Slides 09.11.18 for how it looks(example with the 30p vending machine)
-to implement flip-flops are used to hold the index of the state as a binary number so with n filp-flops
2^n states can be represented(again illustration in slides)

>>Mealy(output depends on the state and input takes less time than Moore) vs
Moore(outputs only depend on the state(if state == 2: out 1) they are
synced with the clock and require more logic;most machines nowadays use this method) machine

>>Logic for resetting is often needed

>>CPU processing speed is significantly faster than memory systems so most of processor time is
spent waiting for data to be fetched from memory, with modern computers a problem is even that the time it takes
for data to get through the motherboard from memory is significant(e.g with a 3 GHz processor). Solutions:
-Faster memory, not very good as static RAM is ~1000 times more expensive than flash RAM
-CPU accesses memory for only two reasons - fetch data or instructions. So you can store instructions in static RAM(cache)
and only access flash memory for data. This speeds things up as an average program accesses memory for data relatively
not often and doesn't make the computer as expensive as using only static RAM but still it would need a lot of static RAM
-Locality, caching and memory hierarchy

>>Locality:
-Spatial - if a bit of memory gets executed the nearby ones are likely to get executed next
-Temporal - if a bit of memory is accessed it is likely to get accessed again soon

>>Caching:
-If a piece of data that CPU wants to access happens to be in cache it is a cache hit if not its a cache miss
-Hit rate: hits/accesses Miss rate: 1 - hitrate
-Hit time: time to access the cache + time it takes to tell if it is a hit or a miss
-Miss penalty - how much time is added if a cache miss happens

>>Stored program computer - to change functionality modify whatever is stored in memory

>>Pipeline
-used to do the three stages(fetch,decode,execute) in parallel
-after the first instruction is fetched in the next clock cycle start decoding it and fetch the second instructions
slides 21.11.18 for illustration
-even though each instruction still takes 3 clock cycles to execute it appears as if there is one instruction execute each cycle
-implemented by adding flipflops(illustration on slides, the blue lines are DFFs)
-pipeline hazards:
  #structural hazard - CPU can only fetch data or instructions at the same time there are(eg LDR instruction in execute stage and another instruction in fetch stage)
  the solution is that the CPU will just execute those instructions in sequence(bubbles, pipeline stalls) (illustration on slides)
